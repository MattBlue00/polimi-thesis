I'll help you with data imputation for this dataset. Let's break it down into steps:

1. First, let's identify the columns that need imputation:
- brokered_by: contains NaN and "-"
- status: contains NaN, "s", "f", and "-"
- price: contains NaN and "-"
- bed: contains NaN, "-", and unrealistic values (9999)
- bath: contains NaN, "-", and "0"
- acre_lot: contains NaN, "-", and negative values
- street: contains NaN and "-"
- city: contains NaN and "-"
- state: contains NaN and "-"
- zip_code: contains NaN and "-"
- house_size: contains NaN, "-", and scientific notation
- prev_sold_date: contains NaN and different date formats

2. Imputation strategies for each column:
- brokered_by: Replace with mode since it's categorical
- status: Map "s" to "sold", "f" to "for_sale", and use mode for NaN/"-"
- price: Remove "$" and convert to numeric, use median for NaN/"-"
- bed: Replace 9999 with NaN, then use median
- bath: Replace 0 with NaN, then use median
- acre_lot: Replace negative values with NaN, then use median
- street/city/state: Use mode or "Unknown"
- zip_code: Use mode
- house_size: Convert scientific notation to regular numbers, use median
- prev_sold_date: Standardize date format, use median date

Here's a Python code outline:

```python
import pandas as pd
import numpy as np
from datetime import datetime

# Convert price to numeric
df['price'] = df['price'].replace('[\$,]', '', regex=True).replace('-', np.nan).astype(float)

# Clean bed column
df['bed'] = df['bed'].replace(9999, np.nan).replace('-', np.nan).astype(float)

# Clean bath column
df['bath'] = df['bath'].replace(0, np.nan).replace('-', np.nan).astype(float)

# Clean acre_lot column
df['acre_lot'] = pd.to_numeric(df['acre_lot'].replace('-', np.nan), errors='coerce')
df.loc[df['acre_lot'] < 0, 'acre_lot'] = np.nan

# Clean status
status_map = {'s': 'sold', 'f': 'for_sale', '-': np.nan}
df['status'] = df['status'].replace(status_map)

# Impute numeric columns with median
numeric_cols = ['price', 'bed', 'bath', 'acre_lot', 'house_size']
for col in numeric_cols:
    df[col] = df[col].fillna(df[col].median())

# Impute categorical columns with mode
categorical_cols = ['brokered_by', 'status', 'street', 'city', 'state', 'zip_code']
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

# Standardize dates
df['prev_sold_date'] = pd.to_datetime(df['prev_sold_date'], errors='coerce')
df['prev_sold_date'] = df['prev_sold_date'].fillna(df['prev_sold_date'].median())
```

3. Additional considerations:
- We might want to create dummy variables for categorical columns
- We could use more sophisticated imputation methods like KNN or MICE
- For location-based data, we could use nearby properties' values
- We might want to add flags indicating which values were imputed

Would you like me to implement any specific part of this plan in more detail?